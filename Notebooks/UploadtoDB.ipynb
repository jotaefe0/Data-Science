{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading DataFrame to SQL DB in AWS\n",
    "We already scraped the Car Data, now we are going to clean it and make some adjustments to upload it to a Cloud server SQL\n",
    "\n",
    "Steps:\n",
    "* import DF from scrapper\n",
    "* clean data\n",
    "* Verify columns names\n",
    "* Upload to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import psycopg2 as ps\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('scrap_final.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Marca\n",
       "Acura                        1\n",
       "Alfa Romeo                 226\n",
       "Aro                          1\n",
       "Audi                      1999\n",
       "Audi A1                      2\n",
       "                          ... \n",
       "Volvo                      164\n",
       "bmw audi mercedes benz       3\n",
       "fiat 600 82                  2\n",
       "izuzu                        1\n",
       "mercedes                     1\n",
       "Length: 94, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.rename(columns={df.columns[9]: 'Tipo de carr'})\n",
    "df.groupby('Marca').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there is a problem with the column names which endes up in NaN values were in reallity there are 3 columns that are the same (This is because of character encoding)\n",
    "This is why we rename all columns into english name to prevent compatibility issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['id'] = df.index\n",
    "new_df['brand'] = df['Marca']\n",
    "new_df['model'] = df['Modelo']\n",
    "new_df['colour'] = df['Color']\n",
    "new_df['fuel'] = df['Tipo de combustible']\n",
    "new_df['doors'] = df['Puertas']\n",
    "new_df['engine'] = df['Motor']\n",
    "new_df['location'] = df['Location']\n",
    "new_df['price'] = df['Price']\n",
    "new_df['year'] = df['Año'].fillna(df['AÃ±o'])\n",
    "if 'TransmisiÃ³n' in df:\n",
    "    new_df['transmision'] = df['Transmisión'].fillna(df['TransmisiÃ³n'])\n",
    "else:\n",
    "    new_df['transmision'] = df['Transmisión']\n",
    "new_df['km'] = df['Kilómetros'].fillna(df['KilÃ³metros'])\n",
    "new_df['type'] = df['Tipo de carrocería'].fillna(df['Tipo de carr'])\n",
    "new_df['url'] = df['Link']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             False\n",
       "brand          False\n",
       "model          False\n",
       "colour          True\n",
       "fuel           False\n",
       "doors          False\n",
       "engine          True\n",
       "location       False\n",
       "price          False\n",
       "year           False\n",
       "transmision     True\n",
       "km             False\n",
       "type            True\n",
       "url            False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see there are some missing values, but at least every car has the main features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also check for duplicates in the URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.duplicated(subset=\"id\").any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df.drop_duplicates(subset=\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As we see we also have a problem with encoding, 2 values ended up beeing 4\n",
    "#### Sure there is a library to handle encoding, I triend .encode and .decode but didnt work. So I decided to replace it myself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'Automática', 'Manual', 'Automática secuencial'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df[\"transmision\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df[\"transmision\"] = new_df[\"transmision\"].str.replace(\"Ã¡\", \"á\",regex=False)\n",
    "new_df[\"fuel\"] = new_df[\"fuel\"].str.replace(\"Ã©\", \"é\",regex=False)\n",
    "new_df[\"fuel\"] = new_df[\"fuel\"].str.replace(\"\\\\\", \"í\",regex=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Also I found this, to normalize and get rid of accents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://stackoverflow.com/a/518232\n",
    "import unicodedata\n",
    "def strip_accents(s):\n",
    "   return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "                  if unicodedata.category(c) != 'Mn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_stripper(serie):\n",
    "    return serie.apply(lambda x:strip_accents(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['fuel'] = series_stripper(new_df['fuel'])\n",
    "new_df['location'] = series_stripper(new_df['location'])\n",
    "new_df['transmision'] = series_stripper(new_df['transmision'].fillna(''))\n",
    "new_df['colour'] = series_stripper(new_df['colour'].fillna('')).str.replace(\"A³\",\"o\",regex=False)\n",
    "new_df['type'] = series_stripper(new_df['type'].fillna(''))\n",
    "new_df[\"brand\"] = new_df[\"brand\"].str.replace(\"Ã«\",\"e\",regex=False).str.replace(\"ë\",\"e\",regex=False).str.replace(\"ÃƒÂ«\",\"e\",regex=False)\n",
    "new_df[\"fuel\"] = new_df[\"fuel\"].str.replace(\"A\\xad\",\"i\",regex=False)\n",
    "new_df[\"km\"] = new_df[\"km\"].str.replace(\" km\",\"\",regex=False).astype(np.int64)\n",
    "new_df[\"type\"] = new_df[\"type\"].str.replace(\"A¡\",\"a\",regex=False).str.replace(\"A³\",\"o\",regex=False).str.replace(\"A©\",\"e\",regex=False)\n",
    "new_df[\"location\"] = new_df[\"location\"].str.replace(\"A¡\",\"a\",regex=False).str.replace(\"A³\",\"o\",regex=False).str.replace(\"A©\",\"e\",regex=False).str.replace(\"A\\xad\",\"i\",regex=False).str.replace(\"A±\",\"n\",regex=False).str.replace(\"Aº\",\"u\",regex=False).str.replace(\"A¼\",\"u\",regex=False)\n",
    "new_df[\"year\"] = new_df[\"year\"].astype(np.int64)\n",
    "new_df[new_df[\"km\"]>1000000]=1000000 #This prevents SQL to get int out of range\n",
    "#Index(['brand', 'model', 'colour', 'fuel', 'doors', 'engine', 'location',\n",
    " #      'price', 'year', 'transmision', 'km', 'type', 'url'],\n",
    "  #    dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Alfa Romeo', 'Audi', 'Volkswagen', 'Ford', 'RAM', 'BMW',\n",
       "       'Audi Q5', 'Citroen', 'Audi A1', 'Renault', 'Audi A3',\n",
       "       'bmw audi mercedes benz', 'Mercedes-Benz', 'Kia', 'VW', 'Mini',\n",
       "       'Acura', 'BMW 640I COUPE', 'Chery', 1000000, 'Chevrolet',\n",
       "       'Peugeot', 'Jeep', 'Chrysler', 'Dodge', 'Crysler', 'DS',\n",
       "       'Dodge Fargo', 'Dacia', 'Fiat', 'FORD V8 4X4', 'Fordd', 'Honda',\n",
       "       'Isuzu', 'Hyundai', 'Jeep ika', 'Toyota', 'Ika', 'Mahindra',\n",
       "       'Daihatsu', 'Land Rover', 'Land rover defender', 'Mazda',\n",
       "       'Mercedes Benz', 'MERCEDEZ BENZ', 'Mini Cooper', 'Lifan', 'Suzuki',\n",
       "       'Pontiac TransSport', 'Mitsubishi', 'Nissan', 'Peugeot  208 like',\n",
       "       'Porsche', 'Smart', 'Subaru', 'Suzuki LJ80', 'Suzuki 1995',\n",
       "       'Volvo', 'Chevrolet Classic', 'CRYSLER TONW & COUNTRY',\n",
       "       'Chrysler stratus lx', 'Citroen c4 feel pack', 'CitroÂ´n',\n",
       "       'Citroen C4 CACTUS', 'Dogde', 'Honda legend', 'Hyunday', 'JMC',\n",
       "       'izuzu', 'Jeep ika continental', 'IKA', 'Ika Renault',\n",
       "       'Escucho oferta Jeep', 'Aro', 'KIA SOULL', 'Range Rover', 'Rover',\n",
       "       'mercedes', 'Mercedez Benz', 'Sprinter', 'Mercedes Benz C250 B',\n",
       "       'Mercedes Benz 1318', 'Shineray', 'Iveco', 'Mini cooper JCW',\n",
       "       'NISSAN NX 2000', 'Nissan datsun', 'Peugeot honda nissan',\n",
       "       'Suzuki Nakai', 'SUZUKY FUN', 'Toyota cross', 'Toyota entrega ya'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique = []\n",
    "unique = new_df.apply(lambda x : x.unique())\n",
    "unique[\"brand\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we got a much cleaner DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'brand', 'model', 'colour', 'fuel', 'doors', 'engine', 'location',\n",
       "       'price', 'year', 'transmision', 'km', 'type', 'url'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We check the types of our DF and translate to SQL types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              int64\n",
       "brand          object\n",
       "model          object\n",
       "colour         object\n",
       "fuel           object\n",
       "doors           int64\n",
       "engine         object\n",
       "location       object\n",
       "price           int64\n",
       "year            int64\n",
       "transmision    object\n",
       "km              int64\n",
       "type           object\n",
       "url            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacements = {\n",
    "    'object':'varchar',\n",
    "    'int64':'int',\n",
    "    'float64':'float'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'id int PRIMARY KEY, brand varchar, model varchar, colour varchar, fuel varchar, doors int, engine varchar, location varchar, price int, year int, transmision varchar, km int, type varchar, url varchar'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_str = \", \".join(\"{} {}\".format(n, d) for (n, d) in zip(new_df.columns[1:], new_df.dtypes[1:].replace(replacements)))\n",
    "\"id int PRIMARY KEY, \" + col_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DB connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "host_name = os.environ.get('SQL_HOST_NAME')\n",
    "dbname = \"postgres\"\n",
    "port = \"5432\"\n",
    "username = os.environ.get('SQL_USER_NAME')\n",
    "password =  os.environ.get('SQL_PASSWORD')\n",
    "conn = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    conn = ps.connect(host=host_name, database=dbname, user=username, password=password, port=port)\n",
    "except ps.OperationalError as e:\n",
    "    raise e\n",
    "else:\n",
    "    print(\"Connected!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table = (f\"\"\"CREATE TABLE IF NOT EXISTS cars ({col_str})\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.autocommit = True\n",
    "curr = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr.execute(create_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv(\"tosqldb_f.csv\", header=new_df.columns, index=False, encoding='utf-8')\n",
    "# cars_data = cars_data.drop(cars_data[cars_data[\"id\"]>40000].index)\n",
    "# csv = open(\"tosqldb.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save and open to insert into DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "COPY_QUERY = \"\"\"\n",
    "COPY cars FROM STDIN WITH CSV HEADER DELIMITER AS ','\n",
    "\"\"\"\n",
    "curr.copy_expert(sql=COPY_QUERY, file=csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr.execute(\"SELECT * FROM cars WHERE year=2019\")\n",
    "curr.fetchone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'AutomÃ¡tica'.encode('latin-1').decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
